{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-W4lDURbX3Rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57de5441-8d8a-4290-bd8b-f4758fe4ae32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['LC_ALL'] = 'C.UTF-8'\n",
        "os.environ['LANG'] = 'C.UTF-8'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VThTUpRq9eAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kr7HWEpmke3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Gz1NyssIogKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Image\n",
        "import image\n",
        "from PIL import Image\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "1_y7DZByY5ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageOps"
      ],
      "metadata": {
        "id": "OQJl9XpCcsr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Z5VzqCgCiZRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "J92wjEYXjBBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "u8oHDMn4ZgK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8m.pt\")"
      ],
      "metadata": {
        "id": "PEC9iulXZDbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e920af-2de5-4056-b0b5-73bf1f192b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 380MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=\"data.yaml\", epochs=50)"
      ],
      "metadata": {
        "id": "xBo2MoCvZkga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470d5660-fd49-475e-b2b5-462e0b6bbec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.47 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 48.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 188MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/FinalTongue/train/labels.cache... 235 images, 4 backgrounds, 0 corrupt: 100%|██████████| 239/239 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/FinalTongue/val/labels.cache... 81 images, 1 backgrounds, 0 corrupt: 100%|██████████| 82/82 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      7.36G      1.053       2.24      1.437         31        640: 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.194      0.309      0.297      0.178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      7.57G      1.002      1.106      1.317         21        640: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.859      0.407      0.541      0.294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      7.59G     0.9889     0.9121      1.357         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81    0.00739      0.642    0.00597    0.00135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      7.57G      1.052     0.8967      1.378         29        640: 100%|██████████| 15/15 [00:06<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81    0.00268      0.519    0.00232   0.000697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      7.58G     0.9948     0.8189      1.313         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81    0.00347      0.815    0.00326    0.00102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      7.58G      1.144      0.902      1.388         28        640: 100%|██████████| 15/15 [00:07<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81     0.0103      0.691     0.0102    0.00465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      7.61G       1.12     0.9141      1.362         28        640: 100%|██████████| 15/15 [00:07<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81    0.00129      0.346   0.000879   0.000367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50       7.6G      1.074     0.8426      1.333         26        640: 100%|██████████| 15/15 [00:07<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81    0.00744      0.494    0.00606    0.00122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      7.58G      1.053     0.7855      1.314         23        640: 100%|██████████| 15/15 [00:07<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81    0.00387      0.309    0.00317   0.000888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50       7.6G      1.082     0.8011      1.357         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81       0.13      0.284     0.0925     0.0527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      7.62G      1.022     0.7456      1.313         22        640: 100%|██████████| 15/15 [00:07<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81     0.0045      0.123    0.00161   0.000783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      7.27G     0.9774     0.6803      1.295         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81       0.57      0.111      0.107     0.0599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      7.24G     0.9965       0.71      1.327         18        640: 100%|██████████| 15/15 [00:07<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.873      0.827      0.873      0.626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      7.27G     0.9729     0.6907      1.266         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.911      0.884      0.962      0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      7.28G     0.9311     0.6375      1.268         33        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.839      0.926      0.959      0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      7.25G     0.9417      0.597      1.273         32        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.983          1      0.983      0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      7.25G     0.9611      0.647      1.276         17        640: 100%|██████████| 15/15 [00:07<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.994      0.983      0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      7.27G     0.9529     0.6348      1.264         22        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.984          1      0.983      0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      7.27G     0.9114     0.6123      1.255         28        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988          1      0.986      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      7.27G     0.8688      0.572      1.235         23        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.964      0.988      0.994      0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      7.24G     0.8767     0.5863      1.225         30        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.932      0.975      0.973      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      7.27G     0.8573     0.5715       1.21         29        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.906      0.828      0.917      0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      7.28G     0.9247     0.6097      1.255         26        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.918          1      0.978      0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      7.26G     0.8594      0.576      1.198         31        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.982          1      0.986       0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      7.24G     0.8553     0.5306      1.199         29        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.986          1      0.985       0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      7.25G     0.8721      0.552      1.205         26        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.975      0.975      0.982      0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      7.27G      0.885     0.5575      1.237         23        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.981          1      0.986      0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      7.26G     0.8426     0.5275      1.189         26        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.971          1      0.985      0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      7.24G     0.8916     0.5418      1.235         28        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.986          1      0.985      0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      7.26G     0.8769     0.5165      1.233         26        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.985      0.988      0.985      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      7.27G     0.8904     0.5156      1.224         27        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.984      0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      7.27G     0.8752     0.5303      1.219         34        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.984      0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      7.24G     0.8172     0.4779      1.177         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.976          1      0.988      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      7.28G     0.8352      0.494      1.207         29        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.984          1      0.987      0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      7.28G     0.8135     0.5183      1.189         25        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.985          1      0.985       0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      7.27G     0.8393     0.4862      1.198         22        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.985      0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      7.24G     0.7847     0.4848      1.177         23        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.984      0.786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      7.27G     0.7902     0.4815      1.159         30        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.984      0.784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      7.28G     0.7936     0.4619       1.17         30        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.983      0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      7.27G     0.7963      0.463      1.153         24        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.983      0.776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      7.24G      0.689     0.4019      1.101         15        640: 100%|██████████| 15/15 [00:08<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.986      0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      7.28G      0.697     0.3881      1.103         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987      0.988      0.978      0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      7.29G     0.6755     0.3815      1.088         13        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987      0.988      0.984      0.776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      7.24G     0.6701     0.3634        1.1         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.988      0.773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      7.25G     0.6705      0.364      1.089         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.987      0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      7.26G     0.6637     0.3555        1.1         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.987          1      0.986      0.781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      7.28G     0.6483      0.342      1.072         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988          1      0.986      0.783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      7.27G     0.6467     0.3429      1.092         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.986      0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      7.25G     0.6461     0.3323      1.072         15        640: 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.986      0.793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      7.27G     0.6496     0.3378      1.092         14        640: 100%|██████████| 15/15 [00:07<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.987      0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.134 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.47 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82         81      0.988      0.999      0.987      0.792\n",
            "Speed: 0.2ms preprocess, 10.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7bcfb84dec80>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.91525,     0.91525,     0.96609,     0.97965,     0.98339,     0.98546,     0.98752,     0.98789,       0.988,      0.9881,      0.9882,      0.9883,      0.9884,     0.98851,     0.98861,     0.98871,     0.98881,     0.98891,     0.98902,     0.98912,     0.98922,     0.98932,     0.98942,\n",
              "            0.98953,     0.98963,     0.98973,     0.98983,     0.98993,     0.99003,     0.99014,     0.99024,     0.99034,     0.99044,     0.99054,     0.99064,     0.99075,     0.99085,     0.99095,     0.99105,     0.99115,     0.99125,     0.99136,     0.99146,     0.99156,     0.99166,     0.99176,\n",
              "            0.99186,     0.99196,     0.99207,     0.99217,     0.99227,     0.99237,     0.99247,     0.99257,     0.99267,     0.99277,     0.99288,     0.99298,     0.99308,     0.99318,     0.99328,     0.99338,     0.99348,     0.99358,     0.99368,     0.99379,     0.99386,     0.99386,     0.99385,\n",
              "            0.99384,     0.99383,     0.99382,     0.99381,     0.99381,      0.9938,     0.99379,     0.99378,     0.99377,     0.99377,     0.99376,     0.99375,     0.99374,     0.99373,     0.99372,     0.99372,     0.99371,      0.9937,     0.99369,     0.99368,     0.99368,     0.99367,     0.99366,\n",
              "            0.99365,     0.99364,     0.99363,     0.99363,     0.99362,     0.99361,      0.9936,     0.99359,     0.99359,     0.99358,     0.99357,     0.99356,     0.99355,     0.99354,     0.99354,     0.99353,     0.99352,     0.99351,      0.9935,      0.9935,     0.99349,     0.99348,     0.99347,\n",
              "            0.99346,     0.99345,     0.99345,     0.99344,     0.99343,     0.99342,     0.99341,     0.99341,      0.9934,     0.99339,     0.99338,     0.99337,     0.99336,     0.99336,     0.99335,     0.99334,     0.99333,     0.99332,     0.99332,     0.99331,      0.9933,     0.99329,     0.99328,\n",
              "            0.99327,     0.99327,     0.99326,     0.99325,     0.99324,     0.99323,     0.99323,     0.99322,     0.99321,      0.9932,     0.99319,     0.99318,     0.99318,     0.99317,     0.99316,     0.99315,     0.99314,     0.99314,     0.99313,     0.99312,     0.99311,      0.9931,     0.99309,\n",
              "            0.99309,     0.99308,     0.99307,     0.99306,     0.99305,     0.99305,     0.99304,     0.99303,     0.99302,     0.99301,       0.993,       0.993,     0.99299,     0.99298,     0.99297,     0.99296,     0.99296,     0.99295,     0.99294,     0.99293,     0.99292,     0.99291,     0.99291,\n",
              "             0.9929,     0.99289,     0.99288,     0.99287,     0.99287,     0.99286,     0.99285,     0.99284,     0.99283,     0.99282,     0.99282,     0.99281,      0.9928,     0.99279,     0.99278,     0.99278,     0.99277,     0.99276,     0.99275,     0.99274,     0.99273,     0.99273,     0.99272,\n",
              "            0.99271,      0.9927,     0.99269,     0.99269,     0.99268,     0.99267,     0.99266,     0.99265,     0.99264,     0.99264,     0.99263,     0.99262,     0.99261,      0.9926,      0.9926,     0.99259,     0.99258,     0.99257,     0.99256,     0.99255,     0.99255,     0.99254,     0.99253,\n",
              "            0.99252,     0.99251,     0.99251,      0.9925,     0.99249,     0.99248,     0.99247,     0.99246,     0.99246,     0.99245,     0.99244,     0.99243,     0.99242,     0.99242,     0.99241,      0.9924,     0.99239,     0.99238,     0.99237,     0.99237,     0.99236,     0.99235,     0.99234,\n",
              "            0.99233,     0.99233,     0.99232,     0.99231,      0.9923,     0.99229,     0.99228,     0.99228,     0.99227,     0.99226,     0.99225,     0.99224,     0.99223,     0.99223,     0.99222,     0.99221,      0.9922,     0.99219,     0.99219,     0.99218,     0.99217,     0.99216,     0.99215,\n",
              "            0.99214,     0.99214,     0.99213,     0.99212,     0.99211,      0.9921,      0.9921,     0.99209,     0.99208,     0.99207,     0.99206,     0.99205,     0.99205,     0.99204,     0.99203,     0.99202,     0.99201,     0.99201,       0.992,     0.99199,     0.99198,     0.99197,     0.99196,\n",
              "            0.99196,     0.99195,     0.99194,     0.99193,     0.99192,     0.99192,     0.99191,      0.9919,     0.99189,     0.99188,     0.99187,     0.99187,     0.99186,     0.99185,     0.99184,     0.99183,     0.99183,     0.99182,     0.99181,      0.9918,     0.99179,     0.99178,     0.99178,\n",
              "            0.99177,     0.99176,     0.99175,     0.99174,     0.99173,     0.99173,     0.99172,     0.99171,      0.9917,     0.99169,     0.99169,     0.99168,     0.99167,     0.99166,     0.99165,     0.99164,     0.99164,     0.99163,     0.99162,     0.99161,      0.9916,      0.9916,     0.99159,\n",
              "            0.99158,     0.99157,     0.99156,     0.99155,     0.99155,     0.99154,     0.99153,     0.99152,     0.99151,     0.99151,      0.9915,     0.99149,     0.99148,     0.99147,     0.99146,     0.99146,     0.99145,     0.99144,     0.99143,     0.99142,     0.99141,     0.99141,      0.9914,\n",
              "            0.99139,     0.99138,     0.99137,     0.99137,     0.99136,     0.99135,     0.99134,     0.99133,     0.99132,     0.99132,     0.99131,      0.9913,     0.99129,     0.99128,     0.99128,     0.99127,     0.99126,     0.99125,     0.99124,     0.99123,     0.99123,     0.99122,     0.99121,\n",
              "             0.9912,     0.99119,     0.99118,     0.99118,     0.99117,     0.99116,     0.99115,     0.99114,     0.99114,     0.99113,     0.99112,     0.99111,      0.9911,     0.99109,     0.99109,     0.99108,     0.99107,     0.99106,     0.99105,     0.99105,     0.99104,     0.99103,     0.99102,\n",
              "            0.99101,       0.991,       0.991,     0.99099,     0.99098,     0.99097,     0.99096,     0.99095,     0.99095,     0.99094,     0.99093,     0.99092,     0.99091,     0.99091,      0.9909,     0.99089,     0.99088,     0.99087,     0.99086,     0.99086,     0.99085,     0.99084,     0.99083,\n",
              "            0.99082,     0.99082,     0.99081,      0.9908,     0.99079,     0.99078,     0.99077,     0.99077,     0.99076,     0.99075,     0.99074,     0.99073,     0.99072,     0.99072,     0.99071,      0.9907,     0.99069,     0.99068,     0.99068,     0.99067,     0.99066,     0.99065,     0.99064,\n",
              "            0.99063,     0.99063,     0.99062,     0.99061,      0.9906,     0.99059,     0.99059,     0.99058,     0.99057,     0.99056,     0.99055,     0.99054,     0.99054,     0.99053,     0.99052,     0.99051,      0.9905,     0.99049,     0.99049,     0.99048,     0.99047,     0.99046,     0.99045,\n",
              "            0.99045,     0.99044,     0.99043,     0.99042,     0.99041,      0.9904,      0.9904,     0.99039,     0.99038,     0.99037,     0.99036,     0.99035,     0.99035,     0.99034,     0.99033,     0.99032,     0.99031,     0.99031,      0.9903,     0.99029,     0.99028,     0.99027,     0.99026,\n",
              "            0.99026,     0.99025,     0.99024,     0.99023,     0.99022,     0.99021,     0.99021,      0.9902,     0.99019,     0.99018,     0.99017,     0.99017,     0.99016,     0.99015,     0.99014,     0.99013,     0.99012,     0.99012,     0.99011,      0.9901,     0.99009,     0.99008,     0.99007,\n",
              "            0.99007,     0.99006,     0.99005,     0.99004,     0.99003,     0.99003,     0.99002,     0.99001,        0.99,     0.98999,     0.98998,     0.98998,     0.98997,     0.98996,     0.98995,     0.98994,     0.98994,     0.98993,     0.98992,     0.98991,      0.9899,     0.98989,     0.98989,\n",
              "            0.98988,     0.98987,     0.98986,     0.98985,     0.98984,     0.98984,     0.98983,     0.98982,     0.98981,      0.9898,      0.9898,     0.98979,     0.98978,     0.98977,     0.98976,     0.98975,     0.98975,     0.98974,     0.98973,     0.98972,     0.98971,      0.9897,      0.9897,\n",
              "            0.98969,     0.98968,     0.98967,     0.98966,     0.98966,     0.98965,     0.98964,     0.98963,     0.98962,     0.98961,     0.98961,      0.9896,     0.98959,     0.98958,     0.98957,     0.98956,     0.98956,     0.98955,     0.98954,     0.98953,     0.98952,     0.98952,     0.98951,\n",
              "             0.9895,     0.98949,     0.98948,     0.98947,     0.98947,     0.98946,     0.98945,     0.98944,     0.98943,     0.98942,     0.98942,     0.98941,      0.9894,     0.98939,     0.98938,     0.98937,     0.98937,     0.98936,     0.98935,     0.98934,     0.98933,     0.98933,     0.98932,\n",
              "            0.98931,      0.9893,     0.98929,     0.98928,     0.98928,     0.98927,     0.98926,     0.98925,     0.98924,     0.98923,     0.98923,     0.98922,     0.98921,      0.9892,     0.98919,     0.98919,     0.98918,     0.98917,     0.98916,     0.98915,     0.98914,     0.98914,     0.98913,\n",
              "            0.98912,     0.98911,      0.9891,     0.98909,     0.98909,     0.98908,     0.98907,     0.98906,     0.98905,     0.98905,     0.98904,     0.98903,     0.98902,     0.98901,       0.989,       0.989,     0.98899,     0.98898,     0.98897,     0.98896,     0.98895,     0.98895,     0.98894,\n",
              "            0.98893,     0.98892,     0.98891,     0.98891,      0.9889,     0.98889,     0.98888,     0.98887,     0.98886,     0.98886,     0.98885,     0.98884,     0.98883,     0.98882,     0.98881,     0.98881,      0.9888,     0.98879,     0.98878,     0.98877,     0.98876,     0.98876,     0.98875,\n",
              "            0.98874,     0.98873,     0.98872,     0.98872,     0.98871,      0.9887,     0.98869,     0.98868,     0.98867,     0.98867,     0.98866,     0.98865,     0.98864,     0.98863,     0.98862,     0.98862,     0.98861,      0.9886,     0.98859,     0.98858,     0.98857,     0.98857,     0.98856,\n",
              "            0.98855,     0.98854,     0.98853,     0.98853,     0.98852,     0.98851,      0.9885,     0.98849,     0.98848,     0.98848,     0.98847,     0.98846,     0.98845,     0.98844,     0.98843,     0.98843,     0.98842,     0.98841,      0.9884,     0.98839,     0.98839,     0.98838,     0.98837,\n",
              "            0.98836,     0.98835,     0.98834,     0.98834,     0.98833,     0.98832,     0.98831,      0.9883,     0.98829,     0.98829,     0.98828,     0.98827,     0.98826,     0.98825,     0.98824,     0.98824,     0.98823,     0.98822,     0.98821,      0.9882,      0.9882,     0.98819,     0.98818,\n",
              "            0.98817,     0.98816,     0.98815,     0.98815,     0.98814,     0.98813,     0.98812,     0.98811,      0.9881,      0.9881,     0.98809,     0.98808,     0.98807,     0.98806,     0.98805,     0.98805,     0.98804,     0.98803,     0.98802,     0.98801,     0.98801,       0.988,     0.98799,\n",
              "            0.98798,     0.98797,     0.98796,     0.98796,     0.98795,     0.98794,     0.98793,     0.98792,     0.98791,     0.98791,      0.9879,     0.98789,     0.98788,     0.98787,     0.98786,     0.98786,     0.98785,     0.98784,     0.98783,     0.98782,     0.98782,     0.98781,      0.9878,\n",
              "            0.98779,     0.98778,     0.98777,     0.98777,     0.98776,     0.98775,     0.98774,     0.98773,     0.98772,     0.98772,     0.98771,      0.9877,     0.98769,     0.98768,     0.98767,     0.98767,     0.98766,     0.98686,     0.98543,       0.984,     0.98257,     0.98121,     0.98028,\n",
              "            0.97936,     0.97842,     0.97749,     0.97656,     0.97562,     0.97055,     0.96808,     0.96753,     0.96697,     0.96642,     0.96586,      0.9653,     0.96474,     0.96419,     0.96363,     0.96307,     0.96251,      0.9619,       0.961,      0.9601,      0.9592,     0.95829,     0.95739,\n",
              "            0.95648,     0.95557,     0.94716,     0.94252,     0.92955,     0.92487,     0.92124,     0.91829,     0.91535,     0.90635,     0.89771,     0.89467,     0.89153,     0.88768,     0.88404,     0.88181,     0.87957,     0.87732,     0.87287,     0.86684,      0.8564,     0.84376,     0.83957,\n",
              "             0.8338,     0.82189,     0.80144,     0.79784,     0.79422,     0.78968,     0.77592,     0.74719,     0.71803,     0.70767,     0.69588,     0.68117,     0.65193,     0.60551,     0.55223,     0.54707,     0.54487,     0.54266,     0.54044,     0.53822,     0.53599,     0.48991,     0.48226,\n",
              "            0.48412,     0.48593,     0.44238,      0.3877,     0.35758,     0.34633,     0.33763,     0.32778,     0.27116,     0.23483,     0.22823,     0.22159,     0.20503,     0.19762,     0.19445,     0.19127,     0.18808,     0.18488,     0.18167,     0.17108,     0.15282,     0.13832,     0.13181,\n",
              "            0.12548,      0.1191,     0.11377,     0.10925,     0.10472,     0.10016,    0.095582,    0.083623,    0.061124,    0.046979,    0.045313,    0.043644,    0.041972,    0.040298,    0.038621,    0.036941,    0.035258,    0.033572,    0.031883,    0.030191,    0.028497,    0.026799,    0.025099,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.84375,     0.84375,     0.93441,     0.96012,     0.96732,     0.97133,     0.97534,     0.97608,     0.97627,     0.97647,     0.97667,     0.97687,     0.97707,     0.97727,     0.97747,     0.97767,     0.97787,     0.97807,     0.97827,     0.97847,     0.97867,     0.97887,     0.97907,\n",
              "            0.97927,     0.97947,     0.97967,     0.97987,     0.98007,     0.98027,     0.98046,     0.98066,     0.98086,     0.98106,     0.98126,     0.98146,     0.98166,     0.98186,     0.98206,     0.98226,     0.98246,     0.98266,     0.98286,     0.98306,     0.98326,     0.98346,     0.98366,\n",
              "            0.98386,     0.98406,     0.98426,     0.98445,     0.98465,     0.98485,     0.98505,     0.98525,     0.98545,     0.98565,     0.98585,     0.98605,     0.98625,     0.98645,     0.98665,     0.98685,     0.98705,     0.98725,     0.98745,     0.98765,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,      0.9878,\n",
              "             0.9878,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,\n",
              "            0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98779,\n",
              "            0.98779,     0.98779,     0.98779,     0.98779,     0.98779,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,\n",
              "            0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,\n",
              "            0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98778,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,\n",
              "            0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,\n",
              "            0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98777,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,\n",
              "            0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,\n",
              "            0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98776,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,\n",
              "            0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,\n",
              "            0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98775,     0.98774,\n",
              "            0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,\n",
              "            0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,     0.98774,\n",
              "            0.98774,     0.98774,     0.98774,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,\n",
              "            0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,\n",
              "            0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98773,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,\n",
              "            0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,\n",
              "            0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98772,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,\n",
              "            0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,\n",
              "            0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,     0.98771,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,\n",
              "             0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,\n",
              "             0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,      0.9877,     0.98769,     0.98769,     0.98769,\n",
              "            0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,\n",
              "            0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,     0.98769,\n",
              "            0.98769,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,\n",
              "            0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98768,\n",
              "            0.98768,     0.98768,     0.98768,     0.98768,     0.98768,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,\n",
              "            0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,\n",
              "            0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98767,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,\n",
              "            0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,\n",
              "            0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98766,     0.98765,     0.98765,     0.98765,     0.98763,      0.9876,     0.98756,     0.98753,      0.9875,     0.98747,\n",
              "            0.98745,     0.98743,      0.9874,     0.98738,     0.98736,     0.98723,     0.98717,     0.98715,     0.98714,     0.98712,     0.98711,      0.9871,     0.98708,     0.98707,     0.98705,     0.98704,     0.98703,     0.98701,     0.98699,     0.98696,     0.98694,     0.98692,     0.98689,\n",
              "            0.98687,     0.98685,     0.98663,      0.9865,     0.98615,     0.98602,     0.98592,     0.98584,     0.98575,      0.9855,     0.98525,     0.98516,     0.98506,     0.98495,     0.98484,     0.98477,      0.9847,     0.98463,      0.9845,     0.98431,     0.98398,     0.98356,     0.98342,\n",
              "            0.98323,     0.98282,     0.98209,     0.98195,     0.98182,     0.98165,     0.98112,     0.97996,     0.97869,     0.97821,     0.97765,     0.97693,      0.9754,     0.97268,     0.96901,     0.96862,     0.96845,     0.96828,     0.96811,     0.96794,     0.96776,     0.96376,     0.96922,\n",
              "            0.98441,     0.99959,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99998,     0.99996,\n",
              "            0.99995,     0.99993,     0.99991,      0.9999,     0.99988,     0.99987,     0.99985,     0.99983,     0.99982,      0.9998,     0.99978,     0.99977,     0.99975,     0.99974,     0.99972,      0.9997,     0.99969,     0.99967,     0.99965,     0.99964,     0.99962,      0.9996,     0.99959,\n",
              "            0.99957,     0.99956,     0.99954,     0.99952,     0.99951,     0.99949,     0.99947,     0.99946,     0.99944,     0.99942,     0.99941,     0.99939,     0.99938,     0.99936,     0.99934,     0.99933,     0.99931,     0.99929,     0.99928,     0.99926,     0.99925,     0.99923,     0.99921,\n",
              "             0.9992,     0.99918,     0.99916,     0.99915,     0.99913,     0.99911,      0.9991,     0.99908,     0.99907,     0.99905,     0.99903,     0.99902,       0.999,     0.99898,     0.99897,     0.99895,     0.99893,     0.99892,      0.9989,     0.99889,     0.99887,     0.99885,     0.99884,\n",
              "            0.99882,      0.9988,     0.99879,     0.99877,     0.99875,     0.99874,     0.99872,     0.99871,     0.99869,     0.99867,     0.99866,     0.99864,     0.99862,     0.99861,     0.99859,     0.99858,     0.99856,     0.99854,     0.99853,     0.99851,     0.99849,     0.99848,     0.99846,\n",
              "            0.99844,     0.99843,     0.99841,      0.9984,     0.99838,     0.99836,     0.99835,     0.99833,     0.99831,      0.9983,     0.99828,     0.99826,     0.99825,     0.99823,     0.99822,      0.9982,     0.99818,     0.99817,     0.99815,     0.99813,     0.99812,      0.9981,     0.99809,\n",
              "            0.99807,     0.99805,     0.99804,     0.99802,       0.998,     0.99799,     0.99797,     0.99795,     0.99794,     0.99792,     0.99791,     0.99789,     0.99787,     0.99786,     0.99784,     0.99782,     0.99781,     0.99779,     0.99777,     0.99776,     0.99774,     0.99773,     0.99771,\n",
              "            0.99769,     0.99768,     0.99766,     0.99764,     0.99763,     0.99761,     0.99759,     0.99758,     0.99756,     0.99755,     0.99753,     0.99751,      0.9975,     0.99748,     0.99746,     0.99745,     0.99743,     0.99742,      0.9974,     0.99738,     0.99737,     0.99735,     0.99733,\n",
              "            0.99732,      0.9973,     0.99728,     0.99727,     0.99725,     0.99724,     0.99722,      0.9972,     0.99719,     0.99717,     0.99715,     0.99714,     0.99712,      0.9971,     0.99709,     0.99707,     0.99706,     0.99704,     0.99702,     0.99701,     0.99699,     0.99697,     0.99696,\n",
              "            0.99694,     0.99693,     0.99691,     0.99689,     0.99688,     0.99686,     0.99684,     0.99683,     0.99681,     0.99679,     0.99678,     0.99676,     0.99675,     0.99673,     0.99671,      0.9967,     0.99668,     0.99666,     0.99665,     0.99663,     0.99661,      0.9966,     0.99658,\n",
              "            0.99657,     0.99655,     0.99653,     0.99652,      0.9965,     0.99648,     0.99647,     0.99645,     0.99643,     0.99642,      0.9964,     0.99639,     0.99637,     0.99635,     0.99634,     0.99632,      0.9963,     0.99629,     0.99627,     0.99626,     0.99624,     0.99622,     0.99621,\n",
              "            0.99619,     0.99617,     0.99616,     0.99614,     0.99612,     0.99611,     0.99609,     0.99608,     0.99606,     0.99604,     0.99603,     0.99601,     0.99599,     0.99598,     0.99596,     0.99594,     0.99593,     0.99591,      0.9959,     0.99588,     0.99586,     0.99585,     0.99583,\n",
              "            0.99581,      0.9958,     0.99578,     0.99577,     0.99575,     0.99573,     0.99572,      0.9957,     0.99568,     0.99567,     0.99565,     0.99563,     0.99562,      0.9956,     0.99559,     0.99557,     0.99555,     0.99554,     0.99552,      0.9955,     0.99549,     0.99547,     0.99545,\n",
              "            0.99544,     0.99542,     0.99541,     0.99539,     0.99537,     0.99536,     0.99534,     0.99532,     0.99531,     0.99529,     0.99527,     0.99526,     0.99524,     0.99523,     0.99521,     0.99519,     0.99518,     0.99516,     0.99514,     0.99513,     0.99511,      0.9951,     0.99508,\n",
              "            0.99506,     0.99505,     0.99503,     0.99501,       0.995,     0.99498,     0.99496,     0.99495,     0.99493,     0.99492,      0.9949,     0.99488,     0.99487,     0.99485,     0.99483,     0.99482,      0.9948,     0.99478,     0.99477,     0.99475,     0.99474,     0.99472,      0.9947,\n",
              "            0.99469,     0.99467,     0.99465,     0.99464,     0.99462,     0.99461,     0.99459,     0.99457,     0.99456,     0.99454,     0.99452,     0.99451,     0.99449,     0.99447,     0.99446,     0.99444,     0.99443,     0.99441,     0.99439,     0.99438,     0.99436,     0.99434,     0.99433,\n",
              "            0.99431,     0.99429,     0.99428,     0.99426,     0.99425,     0.99423,     0.99421,      0.9942,     0.99418,     0.99416,     0.99415,     0.99413,     0.99411,      0.9941,     0.99408,     0.99407,     0.99405,     0.99403,     0.99402,       0.994,     0.99398,     0.99397,     0.99395,\n",
              "            0.99394,     0.99392,      0.9939,     0.99389,     0.99387,     0.99385,     0.99384,     0.99382,      0.9938,     0.99379,     0.99377,     0.99376,     0.99374,     0.99372,     0.99371,     0.99369,     0.99367,     0.99366,     0.99364,     0.99362,     0.99361,     0.99359,     0.99358,\n",
              "            0.99356,     0.99354,     0.99353,     0.99351,     0.99349,     0.99348,     0.99346,     0.99345,     0.99343,     0.99341,      0.9934,     0.99338,     0.99336,     0.99335,     0.99333,     0.99331,      0.9933,     0.99328,     0.99327,     0.99325,     0.99323,     0.99322,      0.9932,\n",
              "            0.99318,     0.99317,     0.99315,     0.99313,     0.99312,      0.9931,     0.99309,     0.99307,     0.99305,     0.99304,     0.99302,       0.993,     0.99299,     0.99297,     0.99296,     0.99294,     0.99292,     0.99291,     0.99289,     0.99287,     0.99286,     0.99284,     0.99282,\n",
              "            0.99281,     0.99279,     0.99278,     0.99276,     0.99274,     0.99273,     0.99271,     0.99269,     0.99268,     0.99266,     0.99264,     0.99263,     0.99261,      0.9926,     0.99258,     0.99256,     0.99255,     0.99253,     0.99251,      0.9925,     0.99248,     0.99246,     0.99245,\n",
              "            0.99243,     0.99242,      0.9924,     0.99238,     0.99237,     0.99235,     0.99233,     0.99232,      0.9923,     0.99229,     0.99227,     0.99225,     0.99224,     0.99222,      0.9922,     0.99219,     0.99217,     0.99215,     0.99214,     0.99212,     0.99211,     0.99209,     0.99207,\n",
              "            0.99206,     0.99204,     0.99202,     0.99201,     0.99199,     0.99197,     0.99196,     0.99194,     0.99193,     0.99191,     0.99189,     0.99188,     0.99186,     0.99184,     0.99183,     0.99181,      0.9918,     0.99178,     0.99176,     0.99175,     0.99173,     0.99171,      0.9917,\n",
              "            0.99168,     0.99166,     0.99165,     0.99163,     0.99162,      0.9916,     0.99158,     0.99157,     0.99155,     0.99153,     0.99152,      0.9915,     0.99148,     0.99147,     0.99145,     0.99144,     0.99142,      0.9914,     0.99139,     0.99137,     0.99135,     0.99134,     0.99132,\n",
              "             0.9913,     0.99129,     0.99127,     0.99126,     0.99124,     0.99122,     0.99121,     0.99119,     0.99117,     0.99116,     0.99114,     0.99113,     0.99111,     0.99109,     0.99108,     0.99106,     0.99104,     0.99103,     0.99101,     0.99099,     0.99098,     0.99096,     0.99095,\n",
              "            0.99093,     0.99091,      0.9909,     0.99088,     0.99086,     0.99085,     0.99083,     0.99081,      0.9908,     0.99078,     0.99077,     0.99075,     0.99073,     0.99072,      0.9907,     0.99068,     0.99067,     0.99065,     0.99064,     0.99062,      0.9906,     0.99059,     0.99057,\n",
              "            0.99055,     0.99054,     0.99052,      0.9905,     0.99049,     0.99047,     0.99046,     0.99044,     0.99042,     0.99041,     0.99039,     0.99037,     0.99036,     0.99034,     0.99032,     0.99031,     0.99029,     0.99028,     0.99026,     0.99024,     0.99023,     0.99021,     0.99019,\n",
              "            0.99018,     0.99016,     0.99014,     0.99013,     0.99011,      0.9901,     0.99008,     0.99006,     0.99005,     0.99003,     0.99001,        0.99,     0.98998,     0.98997,     0.98995,     0.98993,     0.98992,      0.9899,     0.98988,     0.98987,     0.98985,     0.98983,     0.98982,\n",
              "             0.9898,     0.98979,     0.98977,     0.98975,     0.98974,     0.98972,      0.9897,     0.98969,     0.98967,     0.98965,     0.98964,     0.98962,     0.98961,     0.98959,     0.98957,     0.98956,     0.98954,     0.98952,     0.98951,     0.98949,     0.98948,     0.98946,     0.98944,\n",
              "            0.98943,     0.98941,     0.98939,     0.98938,     0.98936,     0.98934,     0.98933,     0.98931,      0.9893,     0.98928,     0.98926,     0.98925,     0.98923,     0.98921,      0.9892,     0.98918,     0.98916,     0.98915,     0.98913,     0.98912,      0.9891,     0.98908,     0.98907,\n",
              "            0.98905,     0.98903,     0.98902,       0.989,     0.98898,     0.98897,     0.98895,     0.98894,     0.98892,      0.9889,     0.98889,     0.98887,     0.98885,     0.98884,     0.98882,     0.98881,     0.98879,     0.98877,     0.98876,     0.98874,     0.98872,     0.98871,     0.98869,\n",
              "            0.98867,     0.98866,     0.98864,     0.98863,     0.98861,     0.98859,     0.98858,     0.98856,     0.98854,     0.98853,     0.98851,     0.98849,     0.98848,     0.98846,     0.98845,     0.98843,     0.98841,      0.9884,     0.98838,     0.98836,     0.98835,     0.98833,     0.98832,\n",
              "             0.9883,     0.98828,     0.98827,     0.98825,     0.98823,     0.98822,      0.9882,     0.98818,     0.98817,     0.98815,     0.98814,     0.98812,      0.9881,     0.98809,     0.98807,     0.98805,     0.98804,     0.98802,       0.988,     0.98799,     0.98797,     0.98796,     0.98794,\n",
              "            0.98792,     0.98791,     0.98789,     0.98787,     0.98786,     0.98784,     0.98782,     0.98781,     0.98779,     0.98778,     0.98776,     0.98774,     0.98773,     0.98771,     0.98769,     0.98768,     0.98766,     0.98609,     0.98328,     0.98046,     0.97765,     0.97501,      0.9732,\n",
              "            0.97139,     0.96958,     0.96778,     0.96597,     0.96416,     0.95442,     0.94972,     0.94867,     0.94761,     0.94656,      0.9455,     0.94445,     0.94339,     0.94234,     0.94128,     0.94023,     0.93918,     0.93803,     0.93634,     0.93466,     0.93297,     0.93128,     0.92959,\n",
              "            0.92791,     0.92622,     0.91073,     0.90229,      0.8791,     0.87086,     0.86453,      0.8594,     0.85434,     0.83897,     0.82446,      0.8194,     0.81422,     0.80789,     0.80195,     0.79834,     0.79472,     0.79111,     0.78398,     0.77442,      0.7581,     0.73875,     0.73243,\n",
              "             0.7238,     0.70625,     0.67693,     0.67187,     0.66681,     0.66051,      0.6417,     0.60378,     0.56701,     0.55436,     0.54019,     0.52287,     0.48958,     0.43958,     0.38615,     0.38118,     0.37907,     0.37696,     0.37485,     0.37274,     0.37063,     0.32843,     0.32099,\n",
              "            0.32099,     0.32099,     0.28401,     0.24046,     0.21772,     0.20943,      0.2031,     0.19602,     0.15685,     0.13303,     0.12882,      0.1246,     0.11423,     0.10964,      0.1077,     0.10575,      0.1038,     0.10186,    0.099909,    0.093544,    0.082733,    0.074297,    0.070554,\n",
              "           0.066938,    0.063323,    0.060313,    0.057782,    0.055252,    0.052721,     0.05019,    0.043636,    0.031525,    0.024054,    0.023182,    0.022309,    0.021436,    0.020563,    0.019691,    0.018818,    0.017945,    0.017072,      0.0162,    0.015327,    0.014454,    0.013581,    0.012709,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.8118310386555264\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.79239])\n",
              "names: {0: 'Tongue'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9877962690514132, 'metrics/recall(B)': 0.9992940622158829, 'metrics/mAP50(B)': 0.9868292682926829, 'metrics/mAP50-95(B)': 0.7923867909180646, 'fitness': 0.8118310386555264}\n",
              "save_dir: PosixPath('runs/detect/train2')\n",
              "speed: {'preprocess': 0.19573583835508765, 'inference': 10.401661803082721, 'loss': 0.00045648435267006476, 'postprocess': 1.2329787742800828}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model('/content/drive/MyDrive/Tongue/train/images/IMG_20220411_094259_jpg.rf.5900516b76a8e34bdf063953c6ec1f8d.jpg')  # results list\n",
        "\n",
        "# Show the results\n",
        "for r in results:\n",
        "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    im.show()  # show image\n",
        "    im.save('results.jpg')  # save image"
      ],
      "metadata": {
        "id": "m-3fgB_FMuHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031ee8bb-e6dc-464f-d124-924e012531ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Tongue/train/images/IMG_20220411_094259_jpg.rf.5900516b76a8e34bdf063953c6ec1f8d.jpg: 640x640 1 Tongue, 37.3ms\n",
            "Speed: 1.7ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming `model` is your Keras model\n",
        "model_path = '/content/drive/MyDrive/FinalTongue/my_model'  # Note: No .h5 extension for SavedModel format\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "gQLnLmml07JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Upload the .h5 file directly\n",
        "uploaded = files.upload()\n",
        "model_path = next(iter(uploaded))  # This gets the name of the uploaded file\n",
        "\n",
        "# Try to load the uploaded model\n",
        "try:\n",
        "    model = load_model(model_path)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to load the model. Error:\", e)"
      ],
      "metadata": {
        "id": "dcBD_Vdd1tJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the model path\n",
        "model_path = '/content/drive/MyDrive/FinalTongue/my_model'\n",
        "\n",
        "# Verify the file path and existence using pathlib\n",
        "model_dir = Path(model_path)\n",
        "if model_dir.is_dir():\n",
        "    print(f\"Model directory exists: {model_path}\")\n",
        "    try:\n",
        "        # Load the model\n",
        "        model = load_model(model_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load the model. Error:\", e)\n",
        "else:\n",
        "    print(f\"Model directory does not exist at: {model_path}\")"
      ],
      "metadata": {
        "id": "hjk20rC21MNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Upload the .h5 file directly\n",
        "uploaded = files.upload()\n",
        "model_path = next(iter(uploaded))  # This gets the name of the uploaded file\n",
        "\n",
        "# Try to load the uploaded model\n",
        "try:\n",
        "    model = load_model(model_path)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to load the model. Error:\", e)"
      ],
      "metadata": {
        "id": "1mPfCqn12Qlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# The oranginal folder path\n",
        "original_folder_path = '/content/drive/MyDrive/FinalTongue/train/images'\n",
        "# The new folder to save the cropped images\n",
        "processed_folder_path = 'cropped_images_train'\n",
        "\n",
        "# If the new folder doesn't exist, then create it\n",
        "os.makedirs(processed_folder_path, exist_ok=True)\n",
        "\n",
        "# Use the glob mode to find all the files with .jpg\n",
        "image_paths = glob.glob(os.path.join(original_folder_path, '*.jpg'))\n",
        "\n",
        "# Use the loop to crop the images\n",
        "for image_path in image_paths:\n",
        "    # load images\n",
        "    image = Image.open(image_path)\n",
        "    # Use the bounding boxes to crop the images\n",
        "    results = model(image_path)\n",
        "    for r in results:\n",
        "      im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "      im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "      boxes = results[0].boxes.xywh.cpu()\n",
        "      for box in boxes:\n",
        "        x, y, w, h = box[:4]\n",
        "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
        "        print(f\"Bounding box coordinates: x={x}, y={y}, w={w}, h={h}\")\n",
        "        if w > 0 and h > 0:\n",
        "          img_cropped = Image.fromarray(np.array(im)).crop((x - w/2 , y - h/2, x + w/2, y + h/2))\n",
        "          filename = os.path.basename(image_path)\n",
        "          processed_image_path = os.path.join(processed_folder_path, filename)\n",
        "          img_cropped.save(processed_image_path)\n",
        "          print(f'The image has been cropped and saved into: {processed_image_path}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P3BGHu3hTu6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4917ee5d-113d-4df6-b21a-ded046fdd536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_106243.jpg: 640x640 1 Tongue, 37.6ms\n",
            "Speed: 2.0ms preprocess, 37.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=382, y=192, w=301, h=203\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_106243.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235252.jpg: 640x640 1 Tongue, 37.1ms\n",
            "Speed: 1.5ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=326, y=132, w=308, h=242\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235252.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235255.jpg: 640x640 1 Tongue, 36.7ms\n",
            "Speed: 1.5ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=285, y=118, w=252, h=175\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235255.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_106245.jpg: 640x640 1 Tongue, 29.2ms\n",
            "Speed: 1.7ms preprocess, 29.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=341, y=168, w=231, h=148\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_106245.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235277.jpg: 640x640 1 Tongue, 29.2ms\n",
            "Speed: 1.6ms preprocess, 29.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=365, y=149, w=291, h=185\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235277.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235279.jpg: 640x640 1 Tongue, 29.2ms\n",
            "Speed: 1.8ms preprocess, 29.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=299, y=251, w=246, h=222\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235279.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235297.jpg: 640x640 1 Tongue, 29.2ms\n",
            "Speed: 1.6ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=274, y=116, w=298, h=233\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235297.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235363.jpg: 640x640 1 Tongue, 27.9ms\n",
            "Speed: 1.6ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=311, y=152, w=365, h=301\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235363.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_106257.jpg: 640x640 1 Tongue, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=301, y=164, w=290, h=200\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_106257.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220411_09235390.jpg: 640x640 1 Tongue, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=315, y=139, w=287, h=279\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220411_09235390.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235497.jpg: 640x640 1 Tongue, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=334, y=209, w=317, h=339\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235497.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235539.jpg: 640x640 1 Tongue, 23.9ms\n",
            "Speed: 1.6ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=319, y=174, w=507, h=293\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235539.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235545.jpg: 640x640 1 Tongue, 23.8ms\n",
            "Speed: 1.6ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=225, y=206, w=318, h=192\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235545.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235548.jpg: 640x640 1 Tongue, 23.2ms\n",
            "Speed: 1.7ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=364, y=122, w=346, h=241\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235548.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235554.jpg: 640x640 1 Tongue, 23.2ms\n",
            "Speed: 1.6ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=313, y=145, w=323, h=270\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235554.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235557.jpg: 640x640 1 Tongue, 21.9ms\n",
            "Speed: 1.6ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=345, y=118, w=219, h=235\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235557.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235581.jpg: 640x640 1 Tongue, 21.9ms\n",
            "Speed: 1.6ms preprocess, 21.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=407, y=161, w=298, h=237\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235581.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235585.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.6ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=313, y=222, w=370, h=247\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235585.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235601.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.6ms preprocess, 21.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=314, y=146, w=349, h=284\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235601.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235620.jpg: 640x640 1 Tongue, 21.4ms\n",
            "Speed: 1.7ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=280, y=272, w=274, h=224\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235620.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235622.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.6ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=351, y=120, w=278, h=187\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235622.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235636.jpg: 640x640 1 Tongue, 21.4ms\n",
            "Speed: 1.6ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=223, y=196, w=228, h=198\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235636.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235647.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.5ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=246, y=221, w=290, h=178\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235647.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235657.jpg: 640x640 1 Tongue, 21.9ms\n",
            "Speed: 1.6ms preprocess, 21.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=328, y=184, w=433, h=276\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235657.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235659.jpg: 640x640 1 Tongue, 21.7ms\n",
            "Speed: 1.6ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=310, y=107, w=325, h=192\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235659.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235680.jpg: 640x640 1 Tongue, 21.4ms\n",
            "Speed: 1.9ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=281, y=176, w=400, h=265\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235680.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235681.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.4ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=321, y=123, w=291, h=246\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235681.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235686.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.4ms preprocess, 21.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=403, y=130, w=348, h=261\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235686.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235688.jpg: 640x640 1 Tongue, 21.3ms\n",
            "Speed: 1.5ms preprocess, 21.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=279, y=208, w=231, h=164\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235688.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235694.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.7ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=386, y=267, w=343, h=230\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235694.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235695.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.4ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=283, y=247, w=248, h=156\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235695.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235703.jpg: 640x640 1 Tongue, 20.3ms\n",
            "Speed: 1.4ms preprocess, 20.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=361, y=155, w=332, h=262\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235703.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220413_09235706.jpg: 640x640 1 Tongue, 20.3ms\n",
            "Speed: 1.3ms preprocess, 20.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=412, y=236, w=324, h=271\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220413_09235706.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235766.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.4ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=282, y=116, w=371, h=233\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235766.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235773.jpg: 640x640 1 Tongue, 20.5ms\n",
            "Speed: 1.5ms preprocess, 20.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=259, y=122, w=365, h=244\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235773.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235776.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.5ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=322, y=177, w=234, h=197\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235776.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235788.jpg: 640x640 1 Tongue, 20.5ms\n",
            "Speed: 1.5ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=282, y=190, w=351, h=241\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235788.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235792.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.5ms preprocess, 20.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=334, y=164, w=252, h=180\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235792.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235804.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.3ms preprocess, 20.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=322, y=188, w=206, h=195\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235804.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_106267.jpg: 640x640 1 Tongue, 20.0ms\n",
            "Speed: 1.4ms preprocess, 20.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=312, y=124, w=226, h=237\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_106267.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235826.jpg: 640x640 1 Tongue, 20.0ms\n",
            "Speed: 1.4ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=364, y=116, w=279, h=226\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235826.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235844.jpg: 640x640 1 Tongue, 21.4ms\n",
            "Speed: 1.4ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=384, y=252, w=270, h=148\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235844.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235847.jpg: 640x640 1 Tongue, 21.5ms\n",
            "Speed: 1.4ms preprocess, 21.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=310, y=130, w=252, h=177\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235847.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235866.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.5ms preprocess, 20.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=293, y=179, w=307, h=178\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235866.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_106271.jpg: 640x640 1 Tongue, 20.4ms\n",
            "Speed: 1.4ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=342, y=151, w=317, h=302\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_106271.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235871.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=324, y=171, w=225, h=157\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235871.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235875.jpg: 640x640 1 Tongue, 19.7ms\n",
            "Speed: 1.4ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=261, y=156, w=306, h=248\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235875.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235876.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=276, y=209, w=217, h=140\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235876.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235896.jpg: 640x640 1 Tongue, 19.7ms\n",
            "Speed: 1.4ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=275, y=225, w=238, h=181\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235896.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235906.jpg: 640x640 1 Tongue, 19.9ms\n",
            "Speed: 1.8ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=406, y=190, w=287, h=166\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235906.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235905.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.6ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=333, y=133, w=266, h=168\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235905.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235909.jpg: 640x640 1 Tongue, 19.4ms\n",
            "Speed: 1.6ms preprocess, 19.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=277, y=214, w=307, h=176\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235909.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09235940.jpg: 640x640 1 Tongue, 19.5ms\n",
            "Speed: 2.1ms preprocess, 19.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=240, y=213, w=297, h=176\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09235940.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09235944.jpg: 640x640 1 Tongue, 19.7ms\n",
            "Speed: 1.5ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=277, y=161, w=299, h=235\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09235944.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09235966.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=268, y=176, w=240, h=183\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09235966.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_106295.jpg: 640x640 1 Tongue, 19.7ms\n",
            "Speed: 1.5ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=344, y=164, w=328, h=274\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_106295.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09235991.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=283, y=131, w=352, h=257\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09235991.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_106304.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=345, y=108, w=425, h=210\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_106304.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236073.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.4ms preprocess, 19.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=300, y=169, w=286, h=243\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236073.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236077.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=367, y=221, w=288, h=249\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236077.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236079.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=296, y=206, w=249, h=179\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236079.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236081.jpg: 640x640 1 Tongue, 19.7ms\n",
            "Speed: 1.4ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=341, y=114, w=304, h=216\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236081.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236087.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.5ms preprocess, 19.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=344, y=120, w=252, h=198\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236087.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236120.jpg: 640x640 1 Tongue, 19.7ms\n",
            "Speed: 1.4ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=239, y=199, w=292, h=185\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236120.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236206.jpg: 640x640 1 Tongue, 19.8ms\n",
            "Speed: 1.4ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=317, y=193, w=333, h=217\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236206.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236211.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.4ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=266, y=141, w=316, h=237\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236211.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236216.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.3ms preprocess, 19.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=369, y=105, w=258, h=125\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236216.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236238.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.4ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=344, y=192, w=288, h=252\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236238.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236250.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.3ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=276, y=111, w=350, h=223\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236250.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236285.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=336, y=203, w=285, h=185\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236285.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236291.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.3ms preprocess, 18.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=315, y=266, w=303, h=324\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236291.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236293.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=321, y=189, w=345, h=293\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236293.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220419_09236302.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.4ms preprocess, 18.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=243, y=194, w=334, h=214\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220419_09236302.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220420_09236402.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.5ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=290, y=235, w=269, h=189\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220420_09236402.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236479.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=259, y=302, w=308, h=236\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236479.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236486.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=267, y=189, w=291, h=221\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236486.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236493.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=262, y=120, w=239, h=238\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236493.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236504.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.5ms preprocess, 19.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=357, y=177, w=309, h=226\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236504.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236536.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.5ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=389, y=185, w=224, h=148\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236536.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236581.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=293, y=153, w=304, h=248\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236581.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236595.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.6ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=309, y=208, w=259, h=196\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236595.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236598.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.6ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=345, y=178, w=294, h=265\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236598.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236604.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.6ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=283, y=164, w=255, h=209\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236604.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220421_09236624.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.6ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=396, y=104, w=295, h=208\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220421_09236624.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220422_09236669.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=213, y=139, w=426, h=278\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220422_09236669.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220422_09236676.jpg: 640x640 1 Tongue, 19.1ms\n",
            "Speed: 1.5ms preprocess, 19.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=326, y=226, w=228, h=169\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220422_09236676.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220422_09236741.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.5ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=386, y=207, w=343, h=256\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220422_09236741.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220422_09236742.jpg: 640x640 1 Tongue, 19.1ms\n",
            "Speed: 1.6ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=240, y=114, w=389, h=228\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220422_09236742.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220422_09236758.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=390, y=217, w=408, h=189\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220422_09236758.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220423_09236792.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.5ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=303, y=203, w=400, h=284\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220423_09236792.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236880.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=254, y=163, w=345, h=278\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236880.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236881.jpg: 640x640 1 Tongue, 18.9ms\n",
            "Speed: 1.4ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=307, y=231, w=301, h=217\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236881.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236889.jpg: 640x640 1 Tongue, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=379, y=246, w=260, h=192\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236889.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236908.jpg: 640x640 1 Tongue, 19.2ms\n",
            "Speed: 1.5ms preprocess, 19.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=302, y=248, w=231, h=225\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236908.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236912.jpg: 640x640 1 Tongue, 19.3ms\n",
            "Speed: 1.4ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=323, y=217, w=267, h=241\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236912.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236922.jpg: 640x640 1 Tongue, 19.2ms\n",
            "Speed: 1.4ms preprocess, 19.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=393, y=158, w=253, h=188\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236922.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236924.jpg: 640x640 1 Tongue, 19.3ms\n",
            "Speed: 1.4ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=337, y=215, w=247, h=153\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236924.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236935.jpg: 640x640 1 Tongue, 19.2ms\n",
            "Speed: 1.5ms preprocess, 19.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=388, y=211, w=274, h=205\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236935.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236938.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.6ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=410, y=124, w=254, h=222\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236938.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236979.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.3ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=307, y=101, w=330, h=202\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236979.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236992.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=338, y=139, w=265, h=165\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236992.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236994.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.5ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=358, y=92, w=237, h=154\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236994.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09237001.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=279, y=182, w=321, h=224\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09237001.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09237002.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=330, y=193, w=217, h=231\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09237002.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09237018.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.3ms preprocess, 18.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=296, y=156, w=405, h=236\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09237018.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09237051.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.6ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=197, y=93, w=339, h=186\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09237051.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237075.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.4ms preprocess, 18.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=401, y=195, w=213, h=153\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237075.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237084.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.3ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=334, y=161, w=334, h=247\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237084.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237085.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.3ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=317, y=308, w=238, h=196\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237085.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237088.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.5ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=369, y=235, w=332, h=219\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237088.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237100.jpg: 640x640 (no detections), 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237107.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.4ms preprocess, 18.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=356, y=266, w=200, h=194\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237107.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237110.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=268, y=106, w=316, h=208\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237110.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237111.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.3ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=390, y=168, w=296, h=206\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237111.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237113.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=341, y=194, w=269, h=234\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237113.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237129.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.5ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=324, y=153, w=270, h=153\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237129.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237134.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.3ms preprocess, 18.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=310, y=172, w=267, h=224\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237134.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237137.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.4ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=406, y=165, w=247, h=189\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237137.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237214.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.6ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=300, y=230, w=239, h=163\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237214.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220426_09237220.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.5ms preprocess, 18.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=322, y=141, w=352, h=282\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220426_09237220.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237236.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.4ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=277, y=245, w=259, h=255\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237236.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237241.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.4ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=352, y=151, w=254, h=140\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237241.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237239.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 2.1ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=312, y=146, w=247, h=265\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237239.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237254.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.6ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=320, y=249, w=227, h=153\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237254.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237260.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.6ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=290, y=238, w=363, h=222\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237260.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237274.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.5ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=271, y=271, w=232, h=191\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237274.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237277.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.4ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=272, y=152, w=214, h=160\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237277.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237284.jpg: 640x640 1 Tongue, 17.9ms\n",
            "Speed: 1.7ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=334, y=207, w=226, h=162\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237284.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237276.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=392, y=76, w=300, h=153\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237276.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220427_09237349.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.4ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=312, y=245, w=208, h=196\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220427_09237349.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220428_09237454.jpg: 640x640 1 Tongue, 17.9ms\n",
            "Speed: 1.5ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=298, y=203, w=345, h=325\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220428_09237454.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220428_09237465.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=348, y=177, w=314, h=163\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220428_09237465.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220428_09237497.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.5ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=390, y=118, w=336, h=223\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220428_09237497.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220429_09237577.jpg: 640x640 1 Tongue, 17.9ms\n",
            "Speed: 1.4ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=458, y=219, w=232, h=170\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220429_09237577.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220429_09237509.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.5ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=390, y=292, w=266, h=299\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220429_09237509.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220429_09237661.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=350, y=274, w=228, h=125\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220429_09237661.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220502_09237879.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.3ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=273, y=117, w=89, h=69\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220502_09237879.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220506_09238592.jpg: 640x640 1 Tongue, 17.9ms\n",
            "Speed: 1.3ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=261, y=150, w=282, h=205\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220506_09238592.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220506_09238604.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.3ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=237, y=179, w=351, h=202\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220506_09238604.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220506_09238607.jpg: 640x640 1 Tongue, 18.0ms\n",
            "Speed: 1.4ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=294, y=162, w=225, h=213\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220506_09238607.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220506_09238634.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.4ms preprocess, 18.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=243, y=261, w=292, h=216\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220506_09238634.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220509_09238860.jpg: 640x640 1 Tongue, 18.8ms\n",
            "Speed: 1.3ms preprocess, 18.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=274, y=200, w=222, h=170\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220509_09238860.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220509_09238882.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=152, y=235, w=231, h=165\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220509_09238882.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220511_09239313.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.5ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=273, y=193, w=301, h=171\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220511_09239313.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220511_09239324.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=190, y=221, w=324, h=271\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220511_09239324.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220511_09239443.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=393, y=114, w=181, h=166\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220511_09239443.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220511_09239445.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.4ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=316, y=97, w=183, h=134\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220511_09239445.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220517_09240402.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.3ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=370, y=172, w=179, h=162\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220517_09240402.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220517_09240404.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.5ms preprocess, 18.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=314, y=195, w=161, h=134\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220517_09240404.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220517_09240415.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=398, y=146, w=206, h=174\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220517_09240415.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220517_09240443.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.5ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=365, y=136, w=213, h=163\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220517_09240443.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220517_09240444.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.4ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=403, y=163, w=204, h=139\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220517_09240444.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220517_09240489.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.5ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=356, y=111, w=147, h=141\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220517_09240489.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220518_09240569.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.7ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=331, y=128, w=177, h=142\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220518_09240569.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245271.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.6ms preprocess, 18.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=296, y=210, w=221, h=111\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245271.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245274.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=281, y=211, w=179, h=235\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245274.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245295.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.9ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=275, y=205, w=312, h=202\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245295.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245301.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.6ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=265, y=217, w=258, h=208\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245301.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245302.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.5ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=241, y=221, w=359, h=235\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245302.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245304.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=256, y=151, w=255, h=183\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245304.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245305.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=265, y=135, w=281, h=205\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245305.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245317.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.4ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=326, y=144, w=369, h=227\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245317.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245313.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.6ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=300, y=237, w=315, h=174\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245313.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245321.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.5ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=386, y=212, w=307, h=270\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245321.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245318.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.4ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=335, y=206, w=168, h=154\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245318.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245325.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.5ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=335, y=226, w=373, h=240\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245325.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_106689.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=333, y=213, w=436, h=308\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_106689.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245428.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.4ms preprocess, 18.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=366, y=196, w=163, h=151\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245428.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220613_09245753.jpg: 640x640 1 Tongue, 18.0ms\n",
            "Speed: 1.4ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=272, y=164, w=216, h=147\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220613_09245753.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220613_09245752.jpg: 640x640 1 Tongue, 18.0ms\n",
            "Speed: 1.4ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=252, y=205, w=220, h=130\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220613_09245752.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220613_09245777.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.3ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=393, y=113, w=235, h=188\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220613_09245777.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220614_09245964.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.3ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=322, y=153, w=188, h=167\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220614_09245964.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220614_09245969.jpg: 640x640 1 Tongue, 18.0ms\n",
            "Speed: 1.3ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=297, y=156, w=121, h=120\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220614_09245969.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220614_106841.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.6ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=295, y=174, w=158, h=116\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220614_106841.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220614_09246006.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=280, y=194, w=204, h=144\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220614_09246006.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246230.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.7ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=350, y=139, w=146, h=123\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246230.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246231.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=289, y=186, w=163, h=141\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246231.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246234.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=357, y=184, w=108, h=112\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246234.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246237.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=375, y=154, w=178, h=154\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246237.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246241.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.3ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=344, y=176, w=140, h=114\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246241.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246242.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.3ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=336, y=301, w=179, h=112\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246242.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246249.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.5ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=403, y=161, w=153, h=138\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246249.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220414_09235867.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=250, y=97, w=329, h=194\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220414_09235867.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220418_09236102.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.4ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=344, y=116, w=333, h=233\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220418_09236102.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236905.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.3ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=458, y=247, w=304, h=236\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236905.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236932.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.4ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=301, y=181, w=244, h=214\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236932.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220425_09236998.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=321, y=99, w=189, h=128\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220425_09236998.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220429_09237608.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.5ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=390, y=292, w=266, h=299\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220429_09237608.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220506_09238648.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.4ms preprocess, 18.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=321, y=176, w=177, h=100\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220506_09238648.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220506_09238649.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.4ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=333, y=160, w=184, h=118\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220506_09238649.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220610_09245291.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.6ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=236, y=181, w=107, h=125\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220610_09245291.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246250.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.4ms preprocess, 18.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=383, y=151, w=110, h=111\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246250.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220615_09246281.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.4ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=296, y=202, w=157, h=153\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220615_09246281.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246492.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.4ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=334, y=140, w=150, h=123\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246492.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246495.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.5ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=297, y=107, w=291, h=128\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246495.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246518.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.5ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=301, y=170, w=213, h=121\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246518.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246523.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.3ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=339, y=229, w=211, h=191\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246523.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246530.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=283, y=152, w=219, h=167\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246530.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246532.jpg: 640x640 1 Tongue, 17.9ms\n",
            "Speed: 1.5ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=284, y=139, w=172, h=139\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246532.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246533.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.5ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=308, y=162, w=171, h=142\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246533.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246592.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=285, y=125, w=209, h=118\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246592.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246599.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.6ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=262, y=180, w=189, h=168\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246599.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246600.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.5ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=272, y=161, w=212, h=147\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246600.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246704.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.5ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=359, y=175, w=158, h=131\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246704.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246721.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.4ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=372, y=113, w=165, h=125\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246721.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246722.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.5ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=344, y=139, w=147, h=142\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246722.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246723.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.6ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=374, y=128, w=154, h=99\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246723.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220616_09246726.jpg: 640x640 1 Tongue, 17.9ms\n",
            "Speed: 1.5ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=361, y=161, w=115, h=106\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220616_09246726.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_106899.jpg: 640x640 1 Tongue, 18.5ms\n",
            "Speed: 1.4ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=269, y=152, w=176, h=130\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_106899.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246831.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.4ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=354, y=263, w=205, h=176\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246831.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246833.jpg: 640x640 1 Tongue, 18.0ms\n",
            "Speed: 1.6ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=263, y=163, w=153, h=119\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246833.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246841.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.5ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=359, y=130, w=154, h=129\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246841.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246849.jpg: 640x640 1 Tongue, 17.7ms\n",
            "Speed: 1.5ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=370, y=231, w=149, h=119\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246849.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246917.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.3ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=335, y=175, w=178, h=133\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246917.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246997.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.5ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=315, y=287, w=222, h=176\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246997.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220617_09246999.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=352, y=247, w=333, h=270\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220617_09246999.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220620_09247422.jpg: 640x640 1 Tongue, 17.8ms\n",
            "Speed: 1.3ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=324, y=208, w=443, h=332\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220620_09247422.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220620_09247423.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.3ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=243, y=210, w=343, h=228\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220620_09247423.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220622_09247784.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=315, y=177, w=449, h=355\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220622_09247784.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220628_09248565.jpg: 640x640 1 Tongue, 17.6ms\n",
            "Speed: 1.5ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=260, y=190, w=236, h=231\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220628_09248565.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220628_107092.jpg: 640x640 1 Tongue, 18.3ms\n",
            "Speed: 1.5ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=299, y=195, w=380, h=330\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220628_107092.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248747.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=460, y=265, w=228, h=163\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248747.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248755.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=312, y=245, w=333, h=276\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248755.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248796.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.5ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=196, y=229, w=242, h=238\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248796.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248802.jpg: 640x640 1 Tongue, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=186, y=172, w=247, h=140\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248802.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248809.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=323, y=301, w=248, h=166\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248809.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248815.jpg: 640x640 1 Tongue, 18.2ms\n",
            "Speed: 1.4ms preprocess, 18.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=275, y=157, w=180, h=144\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248815.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248824.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=270, y=202, w=200, h=181\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248824.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220629_09248826.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=288, y=96, w=166, h=129\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220629_09248826.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220630_09248982.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=345, y=138, w=219, h=173\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220630_09248982.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220630_09249005.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.4ms preprocess, 18.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=405, y=202, w=251, h=190\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220630_09249005.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220630_09249006.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.3ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=341, y=129, w=253, h=158\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220630_09249006.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220701_09249108.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.4ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=378, y=175, w=279, h=189\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220701_09249108.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220701_09249114.jpg: 640x640 1 Tongue, 18.4ms\n",
            "Speed: 1.3ms preprocess, 18.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=262, y=176, w=268, h=182\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220701_09249114.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220701_09249124.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.3ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=291, y=209, w=344, h=242\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220701_09249124.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220701_09249130.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.3ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=340, y=124, w=229, h=155\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220701_09249130.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220701_09249135.jpg: 640x640 1 Tongue, 18.6ms\n",
            "Speed: 1.7ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=216, y=211, w=262, h=190\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220701_09249135.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220701_09249177.jpg: 640x640 1 Tongue, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=243, y=218, w=310, h=178\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220701_09249177.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/FinalTongue/train/images/IMG_20220412_09235541.jpg: 640x640 1 Tongue, 18.0ms\n",
            "Speed: 1.5ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Bounding box coordinates: x=279, y=180, w=375, h=213\n",
            "The image has been cropped and saved into: cropped_images_train/IMG_20220412_09235541.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# The oath of croppped images\n",
        "folder_path = '/content/cropped_images'\n",
        "\n",
        "# Iniialize the maximum width and height\n",
        "max_width = 0\n",
        "max_height = 0\n",
        "\n",
        "# Use the loop to find the maximum values\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "        # Create the folder path\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        # Open the image\n",
        "        with Image.open(file_path) as img:\n",
        "            # Get the height and width of each image\n",
        "            width, height = img.size\n",
        "            # Update the maximum width and height\n",
        "            if width > max_width:\n",
        "                max_width = width\n",
        "            if height > max_height:\n",
        "                max_height = height\n",
        "\n",
        "# Print the realted values\n",
        "print(f\"The widest: {max_width}, The highest: {max_height}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJxcdaaaXPrN",
        "outputId": "4001a3f1-c7f3-406c-ef42-2298151f128d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The widest: 440, The highest: 348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open('/content/resized_images/IMG_20220411_09235231.jpg')\n",
        "\n",
        "# 获取图像尺寸\n",
        "width, height = img.size\n",
        "\n",
        "print(f'Width: {width}, Height: {height}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bQXn7fnEfRh",
        "outputId": "01f828c9-aea7-4a6b-b46a-b78ab4f3cd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width: 524, Height: 524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Target size and color\n",
        "target_width = 440\n",
        "target_height = 440\n",
        "fill_color = (0, 0, 0)  # Padding color is black\n",
        "\n",
        "# Folder path\n",
        "source_folder = '/content/cropped_images'\n",
        "destination_folder = '/content/drive/MyDrive/resized'\n",
        "\n",
        "# create the folder to save resized images（if it doesn't exit）\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "\n",
        "for file_path in glob.glob(os.path.join(source_folder, '*.jpg')):\n",
        "    with Image.open(file_path) as img:\n",
        "        # Calculate the rate\n",
        "        scale = min(target_width / img.width, target_height / img.height)\n",
        "\n",
        "        # Resize the images\n",
        "        new_size = (int(img.width * scale), int(img.height * scale))\n",
        "        img = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "        # Create the new images\n",
        "        new_img = Image.new('RGB', (target_width, target_height), fill_color)\n",
        "\n",
        "        # Calculate the padding area\n",
        "        top_left_x = (target_width - new_size[0]) // 2\n",
        "        top_left_y = (target_height - new_size[1]) // 2\n",
        "\n",
        "        # Paste the new images with padding into the original one\n",
        "        new_img.paste(img, (top_left_x, top_left_y))\n",
        "\n",
        "        # Create the new image path\n",
        "        new_file_path = os.path.join(destination_folder, os.path.basename(file_path))\n",
        "\n",
        "        # Save the resized images\n",
        "        new_img.save(new_file_path)\n",
        "\n",
        "print(\"Resized images has been saved.\")\n"
      ],
      "metadata": {
        "id": "zyKznRVNXaVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34983689-d399-431a-d1a7-5f4f07c78585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-7f8d2fe9d30f>:26: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img = img.resize(new_size, Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized images has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 假设20%的数据用作验证\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/FinalTongue/CNN',  # 数据集目录路径\n",
        "    target_size=(524, 524),  # 指定图像调整后的大小\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # 因为只有两个类别\n",
        "    subset='training')  # 训练数据\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/FinalTongue/CNN',  # 同样的数据集目录路径\n",
        "    target_size=(524, 524),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # 因为只有两个类别\n",
        "    subset='validation')  # 验证数据\n",
        "\n",
        "\n",
        "\n",
        "# 假设 y_true 是真实标签，y_pred 是模型预测的标签\n",
        "y_true = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,1,0,1,0,0,1,0,0,1,1,0,1,0,0,0,1]\n",
        "predictions = model.predict(validation_generator)\n",
        "y_pred = (predictions > 0.25).astype(int).flatten()\n",
        "\n",
        "print(y_pred[:80])  # 打印前10个预测标签\n",
        "# 计算混淆矩阵\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u8TtNRoPMVg",
        "outputId": "ee723914-e3a3-4107-f3d8-3553fa6fb75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 317 images belonging to 2 classes.\n",
            "Found 78 images belonging to 2 classes.\n",
            "3/3 [==============================] - 1s 209ms/step\n",
            "[1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
        "\n",
        "# 初始化存储结果的列表\n",
        "accuracies = []\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "# 重复训练和评估过程十次\n",
        "for i in range(10):\n",
        "    # 数据准备（与之前相同的步骤）\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/FinalTongue/CNN',\n",
        "        target_size=(524, 524),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/FinalTongue/CNN',\n",
        "        target_size=(524, 524),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "    # 构建模型（与之前相同的步骤）\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', input_shape=(524, 524, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 训练模型\n",
        "    history = model.fit(train_generator,\n",
        "                        steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "                        epochs=5,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=validation_generator.n // validation_generator.batch_size)\n",
        "\n",
        "    # 评估模型\n",
        "    _, accuracy = model.evaluate(validation_generator)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # 这里你需要自定义一个方法来获取真实标签和预测标签，以便计算混淆矩阵\n",
        "    # 假设获取了 y_true 和 y_pred\n",
        "    # 例如：\n",
        "    y_true = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,1,0,1,0,0,1,0,0,1,1,0,1,0,0,0,1]\n",
        "    # 使用模型对验证集进行预测\n",
        "    y_pred = [1,0,1,0,1,0,1,1,0,0,1,0,1,1,0,0,0,0,1,1,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,1,1,1,0,0,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,0,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # y_pred = [0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
        "    # 这里的 y_true 和 y_pred 应该从模型预测和真实数据集中得到，这里仅作为占位符\n",
        "\n",
        "    # 计算混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    TP = conf_matrix[1, 1]\n",
        "    TN = conf_matrix[0, 0]\n",
        "    FP = conf_matrix[0, 1]\n",
        "    FN = conf_matrix[1, 0]\n",
        "\n",
        "    # 计算敏感性和特异性\n",
        "    sensitivity = TP / (TP + FN)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificity = TN / (TN + FP)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# 计算平均值和标准差\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "avg_sensitivity = np.mean(sensitivities)\n",
        "std_sensitivity = np.std(sensitivities)\n",
        "avg_specificity = np.mean(specificities)\n",
        "std_specificity = np.std(specificities)\n",
        "\n",
        "# 输出结果\n",
        "print(f'Average Accuracy: {avg_accuracy:.2f}, Standard Deviation: {std_accuracy:.2f}')\n",
        "print(f'Average Sensitivity: {avg_sensitivity:.2f}, Standard Deviation: {std_sensitivity:.2f}')\n",
        "print(f'Average Specificity: {avg_specificity:.2f}, Standard Deviation: {std_specificity:.2f}')\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 假设你有三组数据：accuracies, sensitivities, specificities\n",
        "# 这里使用随机数据作为例子\n",
        "import numpy as np\n",
        "np.random.seed(10)  # 为了结果的可复现性\n",
        "accuracies = np.random.rand(10)  # 假设的准确率数据\n",
        "sensitivities = np.random.rand(10)  # 假设的敏感性数据\n",
        "specificities = np.random.rand(10)  # 假设的特异性数据\n",
        "\n",
        "# 将数据整理成pandas DataFrame，以便于使用seaborn\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'Accuracy': accuracies,\n",
        "    'Sensitivity': sensitivities,\n",
        "    'Specificity': specificities\n",
        "})\n",
        "\n",
        "# 将数据从宽格式转换为长格式，适合作图\n",
        "df_long = pd.melt(df, var_name='Metrics', value_name='Values')\n",
        "\n",
        "# 使用seaborn创建小提琴图\n",
        "sns.violinplot(x='Metrics', y='Values', data=df_long)\n",
        "\n",
        "plt.title('Distribution of Metrics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_q3IluAGINNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
        "\n",
        "# 初始化存储结果的列表\n",
        "accuracies = []\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "# 重复训练和评估过程十次\n",
        "for i in range(10):\n",
        "    # 数据准备（与之前相同的步骤）\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/FinalTongue/CNN',\n",
        "        target_size=(524, 524),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/FinalTongue/CNN',\n",
        "        target_size=(524, 524),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "    # 构建模型（与之前相同的步骤）\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', input_shape=(524, 524, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 训练模型\n",
        "    history = model.fit(train_generator,\n",
        "                        steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "                        epochs=5,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=validation_generator.n // validation_generator.batch_size)\n",
        "\n",
        "    # 评估模型\n",
        "    _, accuracy = model.evaluate(validation_generator)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # 这里你需要自定义一个方法来获取真实标签和预测标签，以便计算混淆矩阵\n",
        "    # 假设获取了 y_true 和 y_pred\n",
        "    # 例如：\n",
        "    y_true = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,1,0,1,0,0,1,0,0,1,1,0,1,0,0,0,1]\n",
        "    # 使用模型对验证集进行预测\n",
        "    y_pred = [1,0,1,0,1,0,1,1,0,0,1,0,1,1,0,0,0,0,1,1,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,1,1,1,0,0,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,0,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # y_pred = [0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
        "    # 这里的 y_true 和 y_pred 应该从模型预测和真实数据集中得到，这里仅作为占位符\n",
        "\n",
        "    # 计算混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    TP = conf_matrix[1, 1]\n",
        "    TN = conf_matrix[0, 0]\n",
        "    FP = conf_matrix[0, 1]\n",
        "    FN = conf_matrix[1, 0]\n",
        "\n",
        "    # 计算敏感性和特异性\n",
        "    sensitivity = TP / (TP + FN)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificity = TN / (TN + FP)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "    accuracy = np.random.random()  # 模拟不同的准确率\n",
        "    sensitivity = np.random.random()  # 模拟不同的敏感性\n",
        "    specificity = np.random.random()\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# 计算平均值和标准差\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "avg_sensitivity = np.mean(sensitivities)\n",
        "std_sensitivity = np.std(sensitivities)\n",
        "avg_specificity = np.mean(specificities)\n",
        "std_specificity = np.std(specificities)\n",
        "\n",
        "# 输出结果\n",
        "print(f'Average Accuracy: {avg_accuracy:.2f}, Standard Deviation: {std_accuracy:.2f}')\n",
        "print(f'Average Sensitivity: {avg_sensitivity:.2f}, Standard Deviation: {std_sensitivity:.2f}')\n",
        "print(f'Average Specificity: {avg_specificity:.2f}, Standard Deviation: {std_specificity:.2f}')\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 假设你有三组数据：accuracies, sensitivities, specificities\n",
        "# 这里使用随机数据作为例子\n",
        "import numpy as np\n",
        "np.random.seed(10)  # 为了结果的可复现性\n",
        "accuracies = np.random.rand(10)  # 假设的准确率数据\n",
        "sensitivities = np.random.rand(10)  # 假设的敏感性数据\n",
        "specificities = np.random.rand(10)  # 假设的特异性数据\n",
        "\n",
        "# 将数据整理成pandas DataFrame，以便于使用seaborn\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'Accuracy': accuracies,\n",
        "    'Sensitivity': sensitivities,\n",
        "    'Specificity': specificities\n",
        "})\n",
        "\n",
        "# 将数据从宽格式转换为长格式，适合作图\n",
        "df_long = pd.melt(df, var_name='Metrics', value_name='Values')\n",
        "\n",
        "# 使用seaborn创建小提琴图\n",
        "sns.violinplot(x='Metrics', y='Values', data=df_long)\n",
        "\n",
        "plt.title('Distribution of Metrics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0JiNZkYvymVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 假设你有三组数据：accuracies, sensitivities, specificities\n",
        "# 这里使用随机数据作为例子\n",
        "import numpy as np\n",
        "np.random.seed(10)  # 为了结果的可复现性\n",
        "accuracies = np.random.rand(10)  # 假设的准确率数据\n",
        "sensitivities = np.random.rand(10)  # 假设的敏感性数据\n",
        "specificities = np.random.rand(10)  # 假设的特异性数据\n",
        "\n",
        "# 将数据整理成pandas DataFrame，以便于使用seaborn\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'Accuracy': accuracies,\n",
        "    'Sensitivity': sensitivities,\n",
        "    'Specificity': specificities\n",
        "})\n",
        "\n",
        "# 将数据从宽格式转换为长格式，适合作图\n",
        "df_long = pd.melt(df, var_name='Metrics', value_name='Values')\n",
        "\n",
        "# 使用seaborn创建小提琴图\n",
        "sns.violinplot(x='Metrics', y='Values', data=df_long)\n",
        "\n",
        "plt.title('Distribution of Metrics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OGUI5m2paA1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "eVaLTzuKS_nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def remove_ipynb_checkpoints(root_dir):\n",
        "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "        if '.ipynb_checkpoints' in dirnames:\n",
        "            shutil.rmtree(os.path.join(dirpath, '.ipynb_checkpoints'))\n",
        "            print(f\"Removed .ipynb_checkpoints from {dirpath}\")\n",
        "\n",
        "# 替换这里的路径为你的数据集根目录\n",
        "root_dir = '/content/drive/MyDrive/FinalTongue/CNN'\n",
        "remove_ipynb_checkpoints(root_dir)\n"
      ],
      "metadata": {
        "id": "Kif_nvBU6wrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "# 数据转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((456, 456)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 加载数据\n",
        "data_dir = '/content/drive/MyDrive/FinalTongue/CNN'\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=f'{data_dir}/train', transform=transform)\n",
        "val_dataset = datasets.ImageFolder(root=f'{data_dir}/val', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# 加载预训练的ResNet18模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 二分类\n",
        "\n",
        "# 损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 训练模型\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 10  # 或者根据需要调整\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "# 评估模型\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
        "specificity = recall_score(y_true, y_pred, pos_label=0)\n",
        "\n",
        "print(f'Accuracy: {accuracy}\\nSensitivity: {sensitivity}\\nSpecificity: {specificity}')\n"
      ],
      "metadata": {
        "id": "ko7_My5x1e4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 图像预处理\n",
        "# 根据你的模型需求调整这里的预处理步骤\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((456, 456)),  # 假设图像已经是224x224，这一步可能不需要\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 加载图像文件夹\n",
        "data_folder = '/content/resized_images'\n",
        "dataset = datasets.ImageFolder(root=data_folder, transform=transform)\n",
        "\n",
        "# 创建数据加载器\n",
        "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)  # batch_size根据需要调整\n",
        "# 假设你已经有了YOLOv8模型实例\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "target_layer = model.get_target_layer(22)  # 你需要实现这一步\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class FeatureExtractor():\n",
        "    \"\"\"用于提取注册的特征的钩子\"\"\"\n",
        "    def __init__(self, model, target_layers):\n",
        "        self.model = model\n",
        "        self.target_layers = target_layers\n",
        "        self.gradients = []\n",
        "\n",
        "        self.hooks = []\n",
        "        for target_layer in target_layers:\n",
        "            target_layer.register_forward_hook(self.save_feature)\n",
        "            target_layer.register_backward_hook(self.save_gradient)\n",
        "\n",
        "    def save_feature(self, module, input, output):\n",
        "        self.features = output\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients.append(grad_output[0])\n",
        "\n",
        "    def get_gradients(self):\n",
        "        return self.gradients\n",
        "\n",
        "    def get_features(self):\n",
        "        return self.features\n",
        "\n",
        "    def remove_hooks(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "\n",
        "def apply_grad_cam(input_image, model, target_layer, target_class):\n",
        "    # 确保模型处于评估模式\n",
        "    model.eval()\n",
        "    target_class = 'Tongue'\n",
        "\n",
        "    # 特征提取器\n",
        "    extractor = FeatureExtractor(model, target_layer)\n",
        "\n",
        "    # 正向传播以获取模型输出\n",
        "    output = model(input_image)\n",
        "    # 假设输出是[N, C, H, W]，其中N是批次大小，C是类别数，H和W是图像的高度和宽度\n",
        "    # 你需要根据YOLO的输出格式来调整这部分\n",
        "\n",
        "    # 使用目标类别计算梯度\n",
        "    model.zero_grad()\n",
        "    class_loss = output[0, target_class].sum()\n",
        "    class_loss.backward()\n",
        "\n",
        "    # 获取特征图和相应的梯度\n",
        "    gradients = extractor.get_gradients()[-1].cpu().data.numpy()[0]\n",
        "    features = extractor.get_features().cpu().data.numpy()[0]\n",
        "\n",
        "    # 权重和特征图加权求和\n",
        "    weights = np.mean(gradients, axis=(1, 2))\n",
        "    cam = np.dot(features.transpose(1, 2, 0), weights).transpose(2, 0, 1)\n",
        "\n",
        "    # 应用ReLU\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam - np.min(cam)\n",
        "    cam = cam / np.max(cam)\n",
        "\n",
        "    # 转换为图像格式\n",
        "    cam_image = np.uint8(255 * cam)\n",
        "    cam_image = np.transpose(cam_image, (1, 2, 0))\n",
        "    input_image = input_image.cpu().data.numpy()[0].transpose(1, 2, 0)\n",
        "    input_image = (input_image - np.min(input_image)) / (np.max(input_image) - np.min(input_image))\n",
        "    cam_image = cv2.resize(cam_image, (input_image.shape[1], input_image.shape[0]))\n",
        "    heatmap = cv2.applyColorMap(cam_image, cv2.COLORMAP_JET)\n",
        "\n",
        "    # 叠加热图和原始图像\n",
        "    final_image = heatmap * 0.3 + input_image * 0.5\n",
        "    cv2.imshow('Grad-CAM', final_image / np.max(final_image))\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # 移除钩子\n",
        "    extractor.remove_hooks()\n",
        "for inputs, _ in data_loader:\n",
        "    # 应用模型获取结果\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # 应用Grad-CAM\n",
        "    cam = apply_grad_cam(inputs, model, target_layer, target_class)\n",
        "\n",
        "    # 可视化或保存Grad-CAM结果\n",
        "    visualize_cam(cam, inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "wUhhUucOZYD2",
        "outputId": "9cdd5b05-6f46-4b05-c4bd-000153936757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Couldn't find any class folder in /content/resized_images.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0eb9ef30b408>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 加载图像文件夹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/resized_images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 创建数据加载器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /content/resized_images."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open('/content/resized_images/IMG_20220419_09236291.jpg')\n",
        "\n",
        "# 获取图像尺寸\n",
        "width, height = img.size\n",
        "\n",
        "print(f'Width: {width}, Height: {height}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMK9qcLCGAPI",
        "outputId": "f1bde589-9ec5-4f4e-84b5-35b836f3d25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Width: 524, Height: 524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.img_paths = []\n",
        "        for root, _, filenames in os.walk(img_dir):\n",
        "            if '.ipynb_checkpoints' in root:\n",
        "                continue\n",
        "            for filename in filenames:\n",
        "                if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')):\n",
        "                    self.img_paths.append(os.path.join(root, filename))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 定义转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # 添加更多的转换如果需要\n",
        "])\n",
        "\n",
        "# 创建数据集和数据加载器\n",
        "dataset = CustomDataset('/content/resized_images', transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "FF-u1rQ2Esvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 131 * 131, 128)  # 根据计算结果更新\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 131 * 131)  # 确保这里的尺寸与fc1层匹配\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9XsNFQ1qCa7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# 自定义数据集的定义保持不变\n",
        "\n",
        "# 数据转换，可以根据需要调整\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((524, 524)),  # 调整图像大小以匹配模型输入\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = CustomDataset('/content/resized_images', transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "model = SimpleCNN(num_classes=1)  # 或者根据你的分类任务调整类别数\n",
        "criterion = nn.BCEWithLogitsLoss()  # 对于二分类任务\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 假设使用GPU训练\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 10  # 或者根据需要调整\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, torch.ones(inputs.size(0), 1).to(device))  # 假设所有样本都是正类\n",
        "        #loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "qaNDNd_lDlHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "class FilteredImageFolder(datasets.ImageFolder):\n",
        "    def __init__(self, root, transform=None, exclude_dirs=None):\n",
        "        self.exclude_dirs = exclude_dirs or []\n",
        "        super().__init__(root, transform=transform)\n",
        "        self.samples = self.filter_samples(self.samples)\n",
        "\n",
        "    def filter_samples(self, samples):\n",
        "        filtered_samples = []\n",
        "        for sample in samples:\n",
        "            if not any(excluded_dir in sample[0] for excluded_dir in self.exclude_dirs):\n",
        "                filtered_samples.append(sample)\n",
        "        return filtered_samples\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 使用 FilteredImageFolder，排除 `.ipynb_checkpoints`\n",
        "dataset = FilteredImageFolder(root='/content/resized_images', transform=transform, exclude_dirs=['.ipynb_checkpoints'])\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "xeD4Nl7ICFYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # 假设图像最终大小为8x8\n",
        "        self.fc2 = nn.Linear(128, 10)  # 假设有10个类别\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64 * 8 * 8)  # 调整形状以匹配全连接层的输入\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 实例化模型、损失函数和优化器\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(datasets.ImageFolder('/content/resized_images', transform=transforms.ToTensor()), batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "# 训练模型\n",
        "epochs = 10  # 设置训练的轮次\n",
        "for epoch in range(epochs):\n",
        "    for data, targets in train_loader:\n",
        "        optimizer.zero_grad()  # 清零梯度\n",
        "        outputs = model(data)  # 前向传播\n",
        "        loss = criterion(outputs, targets)  # 计算损失\n",
        "        loss.backward()  # 反向传播\n",
        "        optimizer.step()  # 更新参数\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "0SWuOMRs7YYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import model_from_yaml\n",
        "\n",
        "# 设置图片和模型路径 (Set image and model path)\n",
        "folder_path = '/content/resized_images'\n",
        "model_path = '/content/my_model.h5'\n",
        "\n",
        "# Attempt to open the file with h5py to check if it's accessible and not corrupted\n",
        "try:\n",
        "    with h5py.File(model_path, \"r\") as file:\n",
        "        print(\"File can be opened, seems not to be corrupted:\", list(file.keys()))\n",
        "        file_accessible = True\n",
        "except Exception as e:\n",
        "    print(\"Failed to open file with h5py. Possible reasons include incorrect path or corrupted file.\")\n",
        "    print(\"Error:\", e)\n",
        "    file_accessible = False\n",
        "\n",
        "# If the file is accessible, proceed to load the model\n",
        "if file_accessible:\n",
        "    try:\n",
        "        model = load_model(model_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load the model. Please check the model file and compatibility with your TensorFlow/Keras version.\")\n",
        "        print(\"Error:\", e)\n",
        "else:\n",
        "    print(\"Model loading skipped due to file access issues.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcpDNbpZyH4f",
        "outputId": "64cc7bf7-62f8-46ba-efac-f72d562d344f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to open file with h5py. Possible reasons include incorrect path or corrupted file.\n",
            "Error: Unable to open file (file signature not found)\n",
            "Model loading skipped due to file access issues.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import h5py\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.models import model_from_yaml\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# 设置图片和模型路径 (Set image and model path)\n",
        "\n",
        "folder_path = '/content/resized_images'\n",
        "\n",
        "model_path = Path('/content/my_model.h5')\n",
        "\n",
        "# Verify the file path and existence using pathlib\n",
        "\n",
        "print(\"Checking if the file exists in the specified path...\")\n",
        "\n",
        "if model_path.is_file():\n",
        "\n",
        "    print(f\"File exists: {model_path}\")\n",
        "\n",
        "    file_accessible = True\n",
        "\n",
        "else:\n",
        "\n",
        "    print(f\"File does not exist at: {model_path}\")\n",
        "\n",
        "    file_accessible = False\n",
        "\n",
        "# If the file is accessible, proceed to load the model\n",
        "\n",
        "if file_accessible:\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Load the model directly using the load_model function\n",
        "\n",
        "        model = load_model(model_path.as_posix())  # Convert Path object to string path\n",
        "\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"Failed to load the model. Please check the model file and compatibility with your TensorFlow/Keras version.\")\n",
        "\n",
        "        print(\"Error:\", e)\n",
        "\n",
        "else:\n",
        "\n",
        "    print(\"Model loading skipped due to file access issues.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEcA64HVzpgF",
        "outputId": "114f380d-9938-44d3-e8be-051535893e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking if the file exists in the specified path...\n",
            "File exists: /content/my_model.h5\n",
            "Failed to load the model. Please check the model file and compatibility with your TensorFlow/Keras version.\n",
            "Error: Unable to open file (file signature not found)\n"
          ]
        }
      ]
    }
  ]
}